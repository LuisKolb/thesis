{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from lkae.utils.data_loading import pkl_dir, load_pkl, root_dir\n",
    "\n",
    "from lkae.utils.data_loading import AuredDataset, RumorWithEvidence\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file) # load experiment config\n",
    "\n",
    "ds = load_pkl(os.path.join(pkl_dir, 'English_train', 'pre-nam-bio.pkl'))\n",
    "\n",
    "sample: RumorWithEvidence = ds[1]\n",
    "# print(json.dumps(sample, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lkae.retrieval.methods.tfidf import TFIDFRetriever\n",
    "from lkae.retrieval.retrieve import retrieve_evidence\n",
    "from lkae.utils.data_loading import pkl_dir, load_pkl\n",
    "\n",
    "ds = load_pkl(os.path.join(pkl_dir, 'English_train', 'pre-nam-bio.pkl'))\n",
    "\n",
    "tfidf_retriever = TFIDFRetriever(k=5)\n",
    "retrieved_data = retrieve_evidence(ds, tfidf_retriever)\n",
    "# print(json.dumps(retrieved_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for retrieval run - R@5: 0.4390 MAP: 0.3903 with config {'retriever_k': 5}\n",
      "0.43899641577060927 0.39030724313022697\n"
     ]
    }
   ],
   "source": [
    "from lkae.utils.write import write_trec_format_output\n",
    "\n",
    "out_dir = '.'\n",
    "\n",
    "trec_filepath = f'TFIDF_English_train_pre-nam-bio.pkl.trec.txt'   \n",
    "write_trec_format_output(trec_filepath, retrieved_data, 'TFIDF')\n",
    "\n",
    "# gold labels available\n",
    "from lkae.utils.scoring import eval_run_retrieval\n",
    "\n",
    "golden_labels_file = os.path.join(root_dir, 'data', 'train_dev_combined_qrels.txt')\n",
    "\n",
    "r5, meanap = [v for v in eval_run_retrieval(trec_filepath, golden_labels_file).values()]\n",
    "\n",
    "print(f'result for retrieval run - R@5: {r5:.4f} MAP: {meanap:.4f} with config {config}')\n",
    "print(r5, meanap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
