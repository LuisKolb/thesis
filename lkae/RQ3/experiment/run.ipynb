{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from lkae.utils.data_loading import pkl_dir, load_pkl, root_dir, AuredDataset, AuthorityPost\n",
    "from lkae.retrieval.retrieve import get_retriever,retrieve_evidence\n",
    "from lkae.verification.verify import get_verifier, Judge, run_verifier_on_dataset\n",
    "from lkae.utils.scoring import eval_run_custom_nofile\n",
    "\n",
    "# import pyterrier as pt\n",
    "# import pyterrier.io as ptio\n",
    "# import pyterrier.pipelines as ptpipelines\n",
    "# from ir_measures import R, MAP    \n",
    "\n",
    "# if not pt.started():\n",
    "#     pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "# walk through the pkl directory and load all the datasets in one of its subdirectories\n",
    "# load each dataset with its subdirectory name and filename as the key\n",
    "# skip non-pkl files\n",
    "for subdir in os.listdir(pkl_dir):\n",
    "    if not os.path.isdir(os.path.join(pkl_dir, subdir)):\n",
    "        continue            \n",
    "    datasets[subdir] = {}\n",
    "    for filename in os.listdir(os.path.join(pkl_dir, subdir)):\n",
    "        if not filename.endswith('.pkl'):\n",
    "            continue\n",
    "        key = os.path.join(subdir, filename)\n",
    "        datasets[subdir][filename.split('.')[0]] = load_pkl(os.path.join(pkl_dir, key))\n",
    "\n",
    "split = 'dev'\n",
    "\n",
    "dataset_split = f'English_{split}'\n",
    "qrel_filename = f'{dataset_split}_qrels.txt'\n",
    "\n",
    "dataset_variations_dict = datasets[dataset_split]\n",
    "print(dataset_variations_dict.keys())\n",
    "\n",
    "# ground truth RQ3\n",
    "gold_file = os.path.join(root_dir, 'data', f'{dataset_split}.jsonl')\n",
    "gold_list = [line for line in jsonlines.open(gold_file)]\n",
    "\n",
    "# select a single variation of the dataset\n",
    "selected_variation = \"pre-nonam-nobio\"\n",
    "dataset: AuredDataset = dataset_variations_dict[selected_variation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bm25__transformers-roberta': {'retriever': <lkae.retrieval.methods.bm25.BM25Retriever at 0x2bb52170bb0>,\n",
       "  'verifier': <lkae.verification.models.transformers_verifier.TransformersVerifier at 0x2bb521705b0>},\n",
       " 'bm25__transformers-bart': {'retriever': <lkae.retrieval.methods.bm25.BM25Retriever at 0x2bb3022bc70>,\n",
       "  'verifier': <lkae.verification.models.transformers_verifier.TransformersVerifier at 0x2bba89b1a20>},\n",
       " 'tfidf__transformers-roberta': {'retriever': <lkae.retrieval.methods.tfidf.TFIDFRetriever at 0x2bba8a66b60>,\n",
       "  'verifier': <lkae.verification.models.transformers_verifier.TransformersVerifier at 0x2bba8baed10>},\n",
       " 'tfidf__transformers-bart': {'retriever': <lkae.retrieval.methods.tfidf.TFIDFRetriever at 0x2bba8bafd60>,\n",
       "  'verifier': <lkae.verification.models.transformers_verifier.TransformersVerifier at 0x2bbab2b1b40>}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load each config and construct its retriever\n",
    "setups = {}\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    configs = json.load(file)\n",
    "\n",
    "    for config in configs['configs']:\n",
    "        exp_fingerprint = f'{config[\"retriever_method\"]}__{config[\"verifier_method\"]}'\n",
    "        \n",
    "        retriever = get_retriever(**config)\n",
    "        verifier = get_verifier(**config)\n",
    "        \n",
    "        setups[exp_fingerprint] = {}\n",
    "        setups[exp_fingerprint]['retriever'] = retriever\n",
    "        setups[exp_fingerprint]['verifier'] = verifier\n",
    "\n",
    "display(setups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bm25': <lkae.retrieval.methods.bm25.BM25Retriever at 0x2bb52014220>,\n",
       " 'tfidf': <lkae.retrieval.methods.tfidf.TFIDFRetriever at 0x2bb521708e0>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load each config and construct its retriever\n",
    "retrievers = {}\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    configs = json.load(file)\n",
    "\n",
    "    for config in configs['configs']:\n",
    "        retriever_label = get_retriever(**config)\n",
    "        retrievers[config['retriever_method']] = retriever_label\n",
    "\n",
    "retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(dataset):\n",
    "    retrieved_ev = []\n",
    "    evidences = item[\"evidence\"]\n",
    "    if evidences is None:\n",
    "        print(f\"skipped {i} because no evidence\")\n",
    "        continue\n",
    "    for ev in evidences:\n",
    "        retrieved_ev.append(AuthorityPost(ev.url, ev.post_id, ev.text, 1, 1))\n",
    "    dataset[i][\"retrieved_evidence\"] = retrieved_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for verification run - Macro-F1: 0.4361 Strict-Macro-F1: 0.4062 with config {'retriever_method': 'tfidf', 'retriever_k': 5, 'verifier_method': 'transformers-bart', 'model': 'facebook/bart-large-mnli'} and TREC FILE c:\\users\\luisk\\projects-win\\thesis\\lkae\\data\\English_dev.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisk\\miniconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for verification run - Macro-F1: 0.4934 Strict-Macro-F1: 0.4783 with config {'retriever_method': 'tfidf', 'retriever_k': 5, 'verifier_method': 'transformers-bart', 'model': 'facebook/bart-large-mnli'} and TREC FILE c:\\users\\luisk\\projects-win\\thesis\\lkae\\data\\English_dev.jsonl\n",
      "result for verification run - Macro-F1: 0.5417 Strict-Macro-F1: 0.5111 with config {'retriever_method': 'tfidf', 'retriever_k': 5, 'verifier_method': 'transformers-bart', 'model': 'facebook/bart-large-mnli'} and TREC FILE c:\\users\\luisk\\projects-win\\thesis\\lkae\\data\\English_dev.jsonl\n",
      "result for verification run - Macro-F1: 0.4841 Strict-Macro-F1: 0.4553 with config {'retriever_method': 'tfidf', 'retriever_k': 5, 'verifier_method': 'transformers-bart', 'model': 'facebook/bart-large-mnli'} and TREC FILE c:\\users\\luisk\\projects-win\\thesis\\lkae\\data\\English_dev.jsonl\n",
      "saved df to results/df_verification.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro-F1</th>\n",
       "      <th>Strict-Macro-F1</th>\n",
       "      <th>Retrieval_Method</th>\n",
       "      <th>Verifier_Method</th>\n",
       "      <th>DS_Settings</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>transformers-roberta</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>59.869791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493412</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>bm25</td>\n",
       "      <td>transformers-bart</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>35.641588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484127</td>\n",
       "      <td>0.455267</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>transformers-bart</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>72.035851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436147</td>\n",
       "      <td>0.406170</td>\n",
       "      <td>bm25</td>\n",
       "      <td>transformers-roberta</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>28.889681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro-F1  Strict-Macro-F1 Retrieval_Method       Verifier_Method  \\\n",
       "2  0.541667         0.511111            tfidf  transformers-roberta   \n",
       "1  0.493412         0.478261             bm25     transformers-bart   \n",
       "3  0.484127         0.455267            tfidf     transformers-bart   \n",
       "0  0.436147         0.406170             bm25  transformers-roberta   \n",
       "\n",
       "       DS_Settings   Time (s)  \n",
       "2  pre-nonam-nobio  59.869791  \n",
       "1  pre-nonam-nobio  35.641588  \n",
       "3  pre-nonam-nobio  72.035851  \n",
       "0  pre-nonam-nobio  28.889681  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# then for every variation of the dataset in ds, run the experiment with each retriever and save the results\n",
    "\n",
    "\n",
    "solomon = Judge(\n",
    "    scale=False,  # ignore scaling, weigh each evidence evenly, except for confidence score given by verifier\n",
    "    ignore_nei=True, # ignore NEI predictions\n",
    ")\n",
    "\n",
    "out_dir = 'results'\n",
    "data = []\n",
    "\n",
    "for exp_fingerprint in setups:\n",
    "    start = time.time()\n",
    "\n",
    "    retrieved_data = retrieve_evidence(dataset, setups[exp_fingerprint]['retriever'])\n",
    "\n",
    "    dataset.add_trec_list_judgements(retrieved_data)\n",
    "\n",
    "    verification_results = run_verifier_on_dataset(\n",
    "        dataset=dataset,\n",
    "        verifier=setups[exp_fingerprint]['verifier'],\n",
    "        judge=solomon,\n",
    "        blind=False,\n",
    "    )\n",
    "\n",
    "    # print(verification_results)\n",
    "\n",
    "    macro_f1, strict_macro_f1 = eval_run_custom_nofile(verification_results, gold_list)\n",
    "\n",
    "    print(\n",
    "        f\"result for verification run - Macro-F1: {macro_f1:.4f} Strict-Macro-F1: {strict_macro_f1:.4f} with config {config}\"\n",
    "    )\n",
    "\n",
    "    wall_time = time.time() - start\n",
    "\n",
    "    retriever, verifier = exp_fingerprint.split('__')\n",
    "    \n",
    "    data.append({\n",
    "        'Macro-F1': macro_f1,\n",
    "        'Strict-Macro-F1': strict_macro_f1,\n",
    "        'Retrieval_Method': retriever, \n",
    "        'Verifier_Method': verifier, \n",
    "        'DS_Settings': selected_variation,\n",
    "        'Time (s)': wall_time,\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_verification = pd.DataFrame(data)\n",
    "\n",
    "df_verification.to_csv(f'{out_dir}/df_verification.csv')\n",
    "print(f'saved df to {out_dir}/df_verification.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_verification.sort_values(by='Macro-F1', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
