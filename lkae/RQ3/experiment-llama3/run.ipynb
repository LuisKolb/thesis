{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['nopre-nam-bio', 'nopre-nam-nobio', 'nopre-nonam-bio', 'nopre-nonam-nobio', 'pre-nam-bio', 'pre-nam-nobio', 'pre-nonam-bio', 'pre-nonam-nobio'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.10 (built by craigm on 2024-08-22 17:33) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from IPython.display import display\n",
    "\n",
    "from lkae.utils.data_loading import pkl_dir, load_pkls, root_dir, AuredDataset\n",
    "from lkae.retrieval.retrieve import get_retriever,retrieve_evidence\n",
    "from lkae.verification.verify import get_verifier, Judge, run_verifier_on_dataset\n",
    "from lkae.utils.scoring import eval_run_custom_nofile\n",
    "\n",
    "datasets = load_pkls(pkl_dir)\n",
    "\n",
    "# possilbe splits: train, dev, train_dev_combined\n",
    "# (test, all_combined don't have \"labels\")\n",
    "split = 'train_dev_combined'\n",
    "\n",
    "dataset_split = f'English_{split}'\n",
    "qrel_filename = f'{dataset_split}_qrels.txt'\n",
    "\n",
    "dataset_variations_dict = datasets[dataset_split]\n",
    "print(dataset_variations_dict.keys())\n",
    "\n",
    "import pyterrier as pt\n",
    "import pyterrier.io as ptio\n",
    "import pyterrier.pipelines as ptpipelines\n",
    "from ir_measures import R, MAP    \n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth RQ3\n",
    "gold_file = os.path.join(root_dir, 'data', f'{dataset_split}.jsonl')\n",
    "gold_list = [line for line in jsonlines.open(gold_file)]\n",
    "\n",
    "# select a set of variations of the dataset\n",
    "selected_variations = [\"nopre-nam-bio\", \"nopre-nonam-nobio\", \"pre-nam-bio\", \"pre-nonam-nobio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rerank-nv-embed-v1__llama3-1-8b': {'retriever': 'rerank-nv-embed-v1',\n",
       "  'verifier': <lkae.verification.models.llama3_azure_ai.Llama3AzureVerifier at 0x164e2903550>},\n",
       " 'rerank-nv-embed-v1__llama3-1-70b': {'retriever': 'rerank-nv-embed-v1',\n",
       "  'verifier': <lkae.verification.models.llama3_azure_ai.Llama3AzureVerifier at 0x164e2903ee0>},\n",
       " 'rerank-nv-embed-v1__llama3-1-405b': {'retriever': 'rerank-nv-embed-v1',\n",
       "  'verifier': <lkae.verification.models.llama3_azure_ai.Llama3AzureVerifier at 0x164e29034c0>}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load each config and construct its retriever\n",
    "setups = {}\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    configs = json.load(file)\n",
    "\n",
    "    for config in configs['configs']:\n",
    "        exp_fingerprint = f'{config[\"retriever_method\"]}__{config[\"verifier_method\"]}'\n",
    "        \n",
    "        # retriever = get_retriever(**config)\n",
    "        verifier = get_verifier(**config)\n",
    "        \n",
    "        setups[exp_fingerprint] = {}\n",
    "        setups[exp_fingerprint]['retriever'] = config[\"retriever_method\"]\n",
    "        setups[exp_fingerprint]['verifier'] = verifier\n",
    "\n",
    "display(setups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solomon = Judge(\n",
    "    scale=False,  # ignore scaling, weigh each evidence evenly, except for confidence score given by verifier\n",
    "    ignore_nei=True, # ignore NEI predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/nopre-nam-bio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-8b on nopre-nam-bio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873dfd13e82f4da7a79c8f88a8b87ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t190971\n",
      "prompt tokens:\t181305\n",
      "completion tokens:\t9666\n",
      "price estimate:\t$0.060287759999999996\n",
      "result for verification run - Macro-F1: 0.5072 Strict-Macro-F1: 0.5008 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-8b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/nopre-nam-bio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-70b on nopre-nam-bio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6223491653d49afad759eded75d8cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t190896\n",
      "prompt tokens:\t181305\n",
      "completion tokens:\t9591\n",
      "price estimate:\t$0.51984954\n",
      "result for verification run - Macro-F1: 0.7089 Strict-Macro-F1: 0.6961 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-70b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/nopre-nam-bio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-405b on nopre-nam-bio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085ec5c0d9914ad5980bedb084f09a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t192449\n",
      "prompt tokens:\t181305\n",
      "completion tokens:\t11144\n",
      "price estimate:\t$0.9787469000000001\n",
      "result for verification run - Macro-F1: 0.7100 Strict-Macro-F1: 0.6913 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-405b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/nopre-nonam-nobio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-8b on nopre-nonam-nobio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8081e5930fb84dbdba08bdf86d3edc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t363570\n",
      "prompt tokens:\t344182\n",
      "completion tokens:\t19388\n",
      "price estimate:\t$0.11508128000000001\n",
      "result for verification run - Macro-F1: 0.5801 Strict-Macro-F1: 0.5684 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-8b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/nopre-nonam-nobio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-70b on nopre-nonam-nobio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357df7a56f9b48b180df5151c4a2ac1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t363367\n",
      "prompt tokens:\t344182\n",
      "completion tokens:\t19185\n",
      "price estimate:\t$0.99032266\n",
      "result for verification run - Macro-F1: 0.7672 Strict-Macro-F1: 0.7595 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-70b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/nopre-nonam-nobio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-405b on nopre-nonam-nobio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833a2fa80a7844d09e54f86834805051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t365570\n",
      "prompt tokens:\t344182\n",
      "completion tokens:\t21388\n",
      "price estimate:\t$1.8583854\n",
      "result for verification run - Macro-F1: 0.7464 Strict-Macro-F1: 0.7355 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-405b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/pre-nam-bio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-8b on pre-nam-bio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a629536f0d7040899066e0ace9f06093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t534895\n",
      "prompt tokens:\t505925\n",
      "completion tokens:\t28970\n",
      "price estimate:\t$0.16944919999999997\n",
      "result for verification run - Macro-F1: 0.6314 Strict-Macro-F1: 0.6209 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-8b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/pre-nam-bio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-70b on pre-nam-bio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5642d61f6ed84c7fb4dede916d1aac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t534736\n",
      "prompt tokens:\t505925\n",
      "completion tokens:\t28811\n",
      "price estimate:\t$1.4578699400000001\n",
      "result for verification run - Macro-F1: 0.7052 Strict-Macro-F1: 0.6923 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-70b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/pre-nam-bio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-405b on pre-nam-bio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9e5fdacc8a4d739a4f4fe59a5b7e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t536975\n",
      "prompt tokens:\t505925\n",
      "completion tokens:\t31050\n",
      "price estimate:\t$2.7310825\n",
      "result for verification run - Macro-F1: 0.7210 Strict-Macro-F1: 0.7020 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-405b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/pre-nonam-nobio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-8b on pre-nonam-nobio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e837e27cb0a4a49b6f74e4728be23da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not json-parse response from Azure API: I cannot provide a response that supports a conspiracy theory. Is there something else I can help you with?, returning NOT ENOUGH INFO answer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t690603\n",
      "prompt tokens:\t651991\n",
      "completion tokens:\t38612\n",
      "price estimate:\t$0.21915061999999996\n",
      "result for verification run - Macro-F1: 0.6091 Strict-Macro-F1: 0.5975 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-8b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/pre-nonam-nobio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-70b on pre-nonam-nobio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6364c2301ad446aeba41cb1e97ce5aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t690449\n",
      "prompt tokens:\t651991\n",
      "completion tokens:\t38458\n",
      "price estimate:\t$1.8834772000000002\n",
      "result for verification run - Macro-F1: 0.7743 Strict-Macro-F1: 0.7625 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-70b\n",
      "loaded retrieval results from c:\\users\\luisk\\projects-win\\thesis\\lkae/RQ1/experiment-train_dev_combined/results/pre-nonam-nobio_rerank-nv-embed-v1.pkl\n",
      "running rerank-nv-embed-v1__llama3-1-405b on pre-nonam-nobio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863cd35b9b0f42a0a022bb96d4fec589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----total token usage for verification-----\n",
      "total tokens:\t692830\n",
      "prompt tokens:\t651991\n",
      "completion tokens:\t40839\n",
      "price estimate:\t$3.5208947\n",
      "result for verification run - Macro-F1: 0.7668 Strict-Macro-F1: 0.7517 with retriever: rerank-nv-embed-v1 and retriever: llama3-1-405b\n",
      "saved df to results/df_verification.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro-F1</th>\n",
       "      <th>Strict-Macro-F1</th>\n",
       "      <th>Retrieval_Method</th>\n",
       "      <th>Verifier_Method</th>\n",
       "      <th>DS_Settings</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.774271</td>\n",
       "      <td>0.762466</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-70b</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>848.446947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767206</td>\n",
       "      <td>0.759516</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-70b</td>\n",
       "      <td>nopre-nonam-nobio</td>\n",
       "      <td>863.011265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.766809</td>\n",
       "      <td>0.751714</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-405b</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>768.592623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.746368</td>\n",
       "      <td>0.735498</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-405b</td>\n",
       "      <td>nopre-nonam-nobio</td>\n",
       "      <td>791.743006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721013</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-405b</td>\n",
       "      <td>pre-nam-bio</td>\n",
       "      <td>746.702997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-405b</td>\n",
       "      <td>nopre-nam-bio</td>\n",
       "      <td>839.955027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708889</td>\n",
       "      <td>0.696105</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-70b</td>\n",
       "      <td>nopre-nam-bio</td>\n",
       "      <td>730.069102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.705238</td>\n",
       "      <td>0.692306</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-70b</td>\n",
       "      <td>pre-nam-bio</td>\n",
       "      <td>1028.190726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.631411</td>\n",
       "      <td>0.620890</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-8b</td>\n",
       "      <td>pre-nam-bio</td>\n",
       "      <td>230.790539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.609150</td>\n",
       "      <td>0.597481</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-8b</td>\n",
       "      <td>pre-nonam-nobio</td>\n",
       "      <td>278.862560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580128</td>\n",
       "      <td>0.568376</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-8b</td>\n",
       "      <td>nopre-nonam-nobio</td>\n",
       "      <td>231.056547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.507168</td>\n",
       "      <td>0.500789</td>\n",
       "      <td>rerank-nv-embed-v1</td>\n",
       "      <td>llama3-1-8b</td>\n",
       "      <td>nopre-nam-bio</td>\n",
       "      <td>229.015360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Macro-F1  Strict-Macro-F1    Retrieval_Method Verifier_Method  \\\n",
       "10  0.774271         0.762466  rerank-nv-embed-v1    llama3-1-70b   \n",
       "4   0.767206         0.759516  rerank-nv-embed-v1    llama3-1-70b   \n",
       "11  0.766809         0.751714  rerank-nv-embed-v1   llama3-1-405b   \n",
       "5   0.746368         0.735498  rerank-nv-embed-v1   llama3-1-405b   \n",
       "8   0.721013         0.701967  rerank-nv-embed-v1   llama3-1-405b   \n",
       "2   0.709957         0.691318  rerank-nv-embed-v1   llama3-1-405b   \n",
       "1   0.708889         0.696105  rerank-nv-embed-v1    llama3-1-70b   \n",
       "7   0.705238         0.692306  rerank-nv-embed-v1    llama3-1-70b   \n",
       "6   0.631411         0.620890  rerank-nv-embed-v1     llama3-1-8b   \n",
       "9   0.609150         0.597481  rerank-nv-embed-v1     llama3-1-8b   \n",
       "3   0.580128         0.568376  rerank-nv-embed-v1     llama3-1-8b   \n",
       "0   0.507168         0.500789  rerank-nv-embed-v1     llama3-1-8b   \n",
       "\n",
       "          DS_Settings     Time (s)  \n",
       "10    pre-nonam-nobio   848.446947  \n",
       "4   nopre-nonam-nobio   863.011265  \n",
       "11    pre-nonam-nobio   768.592623  \n",
       "5   nopre-nonam-nobio   791.743006  \n",
       "8         pre-nam-bio   746.702997  \n",
       "2       nopre-nam-bio   839.955027  \n",
       "1       nopre-nam-bio   730.069102  \n",
       "7         pre-nam-bio  1028.190726  \n",
       "6         pre-nam-bio   230.790539  \n",
       "9     pre-nonam-nobio   278.862560  \n",
       "3   nopre-nonam-nobio   231.056547  \n",
       "0       nopre-nam-bio   229.015360  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# then for every variation of the dataset in ds, run the experiment with each retriever and save the results\n",
    "\n",
    "out_dir = 'results'\n",
    "data = []\n",
    "\n",
    "\n",
    "for dataset_variation in selected_variations:\n",
    "\n",
    "    for exp_fingerprint in setups:\n",
    "        # get the dataset here since it is modified in place here, contrary to RQ2\n",
    "        dataset: AuredDataset = dataset_variations_dict[dataset_variation]\n",
    "        start = time.time()\n",
    "\n",
    "        # retrieved_data = retrieve_evidence(dataset, setups[exp_fingerprint]['retriever'])\n",
    "        data_path = f'{root_dir}/RQ1/experiment-{split}/results/{dataset_variation}_{setups[exp_fingerprint][\"retriever\"]}.pkl'\n",
    "        retrieved_data = pkl.load(open(data_path, 'rb'))\n",
    "        print(f'loaded retrieval results from {data_path}')\n",
    "\n",
    "        dataset.add_trec_list_judgements(retrieved_data)\n",
    "\n",
    "        run_filename = f'{out_dir}/{dataset_variation}_{exp_fingerprint}.pkl'\n",
    "\n",
    "        # check if the file already exists from a previous run\n",
    "        if os.path.exists(run_filename):\n",
    "            print(f'found {run_filename}, loading from file')\n",
    "            verification_results = pkl.load(open(run_filename, 'rb'))\n",
    "        else:\n",
    "            print(f'running {exp_fingerprint} on {dataset_variation}')\n",
    "            verification_results = run_verifier_on_dataset(\n",
    "                dataset=dataset,\n",
    "                verifier=setups[exp_fingerprint]['verifier'],\n",
    "                judge=solomon,\n",
    "                blind=False,\n",
    "            )\n",
    "            pkl.dump(verification_results, open(run_filename, 'wb'))\n",
    "\n",
    "        # print(verification_results)\n",
    "\n",
    "        macro_f1, strict_macro_f1 = eval_run_custom_nofile(verification_results, gold_list)\n",
    "\n",
    "        retriever_label, verifier_label = exp_fingerprint.split('__')\n",
    "\n",
    "        print(\n",
    "            f\"result for verification run - Macro-F1: {macro_f1:.4f} Strict-Macro-F1: {strict_macro_f1:.4f} with retriever: {retriever_label} and retriever: {verifier_label}\"\n",
    "        )\n",
    "\n",
    "        wall_time = time.time() - start\n",
    "\n",
    "        data.append({\n",
    "            'Macro-F1': macro_f1,\n",
    "            'Strict-Macro-F1': strict_macro_f1,\n",
    "            'Retrieval_Method': retriever_label, \n",
    "            'Verifier_Method': verifier_label, \n",
    "            'DS_Settings': dataset_variation,\n",
    "            'Time (s)': wall_time,\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_verification = pd.DataFrame(data)\n",
    "\n",
    "df_verification.to_csv(f'{out_dir}/df_verification.csv')\n",
    "print(f'saved df to {out_dir}/df_verification.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_verification.sort_values(by='Macro-F1', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
